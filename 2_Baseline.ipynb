{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUrADaqGCphn"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esSfdM-CCpho"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
        "import torch\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx1M_ivCCpho"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def load_data(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    texts = [\n",
        "        {\"id\": record.get(\"title\", f\"doc_{i}\"), \"text\": record.get(\"doc\", \"\")}\n",
        "        for i, record in enumerate(data)\n",
        "    ]\n",
        "\n",
        "    unique_labels = {\n",
        "        label\n",
        "        for record in data\n",
        "        for label in record.get(\"entity_label_set\", [])\n",
        "    }\n",
        "\n",
        "    print(f\"Loaded {len(texts)} texts.\")\n",
        "    file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "    return texts, unique_labels, file_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFk311ClCphp"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "]\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "outputs = pipeline(\n",
        "    messages,\n",
        "    max_new_tokens=256,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "print(outputs[0][\"generated_text\"][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXMKdbuTCphp"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def extract_entities(text: str, labels: list) -> dict:\n",
        "    \"\"\"\n",
        "    Prompt the LLaMA model to extract entities of interest and return a dict mapping labels to lists of entities.\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "      {\"role\": \"system\", \"content\": f\"You are an expert in Named Entity Recognition. Please extract entities that match the schema definition from the input. Return an empty list if the entity type does not exist. Please respond in the format of a JSON string.\\\", \\\"schema\\\": {labels}\"},\n",
        "      {\"role\": \"user\", \"content\": text},\n",
        "    ]\n",
        "\n",
        "    terminators = [\n",
        "        pipeline.tokenizer.eos_token_id,\n",
        "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "    ]\n",
        "\n",
        "    outputs = pipeline(\n",
        "        messages,\n",
        "        max_new_tokens=2048,\n",
        "        eos_token_id=terminators,\n",
        "        do_sample=True,\n",
        "        temperature=0.6,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "    return(outputs[0][\"generated_text\"][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJfK9DS9Cphq"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "from typing import Optional, Dict, Any\n",
        "\n",
        "def convert_model_output_to_json(\n",
        "    title: str,\n",
        "    model_output: str,\n",
        "    output_path: Optional[str] = None\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Extracts a JSON object from a model output string and returns it as a Python dict.\n",
        "    If `output_path` is provided, also writes the JSON to that file.\n",
        "\n",
        "    Args:\n",
        "        model_output: The raw string returned by the model, containing a JSON snippet.\n",
        "        output_path: Optional path (including '.json') to save the extracted JSON.\n",
        "\n",
        "    Returns:\n",
        "        A Python dict representing the JSON data.\n",
        "    \"\"\"\n",
        "    fence_match = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", model_output, re.DOTALL)\n",
        "    if fence_match:\n",
        "        json_str = fence_match.group(1)\n",
        "    else:\n",
        "        start = model_output.find('{')\n",
        "        end = model_output.rfind('}') + 1\n",
        "        if start == -1 or end == -1:\n",
        "            raise ValueError(\"No JSON object found in the model output.\")\n",
        "        json_str = model_output[start:end]\n",
        "\n",
        "    try:\n",
        "        data = json.loads(json_str)\n",
        "    except json.JSONDecodeError as e:\n",
        "        raise ValueError(f\"Failed to parse JSON: {e}\")\n",
        "\n",
        "    new_entry = {title: data}\n",
        "\n",
        "    if output_path:\n",
        "        if os.path.exists(output_path):\n",
        "            with open(output_path, 'r', encoding='utf-8') as f:\n",
        "                try:\n",
        "                    existing_data = json.load(f)\n",
        "                    if not isinstance(existing_data, list):\n",
        "                        existing_data = [existing_data]\n",
        "                except json.JSONDecodeError:\n",
        "                    existing_data = []\n",
        "            existing_data.append(new_entry)\n",
        "            data_to_write = existing_data\n",
        "        else:\n",
        "            data_to_write = [new_entry]\n",
        "\n",
        "        print(f\"Writing JSON to {output_path}\")\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data_to_write, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    return data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSTDDBWECphq"
      },
      "outputs": [],
      "source": [
        "base_folder = \"/content/drive/MyDrive/project_files/data/raw/dev\"\n",
        "\n",
        "for root, dirs, files in os.walk(base_folder):\n",
        "    for filename in files:\n",
        "        path = os.path.join(root, filename)\n",
        "\n",
        "        texts, label_set, file_name = load_data(path)\n",
        "        print(file_name)\n",
        "\n",
        "        for item in texts:\n",
        "\n",
        "            id = item[\"id\"]\n",
        "            text = item[\"text\"]\n",
        "\n",
        "            result = extract_entities(text, label_set)\n",
        "\n",
        "            output_file = f\"/content/drive/MyDrive/project_files/data/processed/baseline_output/{file_name}.json\"\n",
        "\n",
        "            try:\n",
        "              convert_model_output_to_json(id, result[\"content\"], output_file)\n",
        "            except:\n",
        "              print(f\"Could not convert {id}. Saving raw conetent\")\n",
        "              with open(f\"/content/drive/MyDrive/project_files/data/processed/baseline_output/{id}.json\", \"w\") as f:\n",
        "                f.write(result[\"content\"])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}