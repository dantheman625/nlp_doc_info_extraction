{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "300eb73b",
      "metadata": {
        "id": "300eb73b"
      },
      "source": [
        "# Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a9273274",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9273274",
        "outputId": "78e2d5a5-90fa-43fa-830e-e177518eb11d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets torch seqeval evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff5f51e5",
      "metadata": {
        "id": "ff5f51e5"
      },
      "source": [
        "# Env Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5558fb9a",
      "metadata": {
        "id": "5558fb9a"
      },
      "outputs": [],
      "source": [
        "base_path = 'data/'\n",
        "max_token_length = 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53def38a",
      "metadata": {
        "id": "53def38a"
      },
      "source": [
        "# Establish Google Drive Connection (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "785ce452",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "785ce452",
        "outputId": "fef05cc2-3824-4f72-94a5-60e997a4011d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5f0b0d002974>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'drive/MyDrive/dataset/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_path = 'drive/MyDrive/dataset/'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4192d65",
      "metadata": {
        "id": "b4192d65"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "205b781e",
      "metadata": {
        "id": "205b781e"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    LongformerTokenizerFast,\n",
        "    LongformerForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    pipeline,\n",
        "    TrainerCallback,\n",
        "    TrainerState,\n",
        "    TrainerControl,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "import evaluate\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import torch\n",
        "from collections import Counter\n",
        "from typing import Dict, Any"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a32ad725",
      "metadata": {
        "id": "a32ad725"
      },
      "source": [
        "# Helper Functions\n",
        "\n",
        "## Load Data\n",
        "Loads all json files in a specified path and combines them in one aggregated list\n",
        "\n",
        "## Convert Numpy Floats\n",
        "\n",
        "## Save Model Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31d8299a",
      "metadata": {
        "id": "31d8299a"
      },
      "outputs": [],
      "source": [
        "def load_json_data(folder_path):\n",
        "    aggregated_data = []\n",
        "\n",
        "    # loop through all files in the given folder\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file_name in files:\n",
        "            with open(f\"{folder_path}/{file_name}\", \"r\") as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            aggregated_data.append(data)\n",
        "\n",
        "    return aggregated_data\n",
        "\n",
        "# Convert NumPy float32 to native Python floats before JSON serialization\n",
        "def convert_numpy_floats(obj):\n",
        "    if isinstance(obj, np.float32):\n",
        "        return float(obj)\n",
        "    raise TypeError\n",
        "\n",
        "def save_model_output(output, output_path):\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(output, f, ensure_ascii=False, indent=2, default=convert_numpy_floats)\n",
        "    print(f\"Saved validation NER predictions to {output_path}\")\n",
        "\n",
        "def compute_f1(predictions_file_path, output_path, validation_dataset):\n",
        "  # Load saved predictions\n",
        "  with open(predictions_file_path, 'r') as f:\n",
        "      saved_preds = json.load(f)\n",
        "\n",
        "  # Prepare gold and predicted lists\n",
        "  all_gold = []\n",
        "  all_pred = []\n",
        "  for pred in saved_preds:\n",
        "      idx = pred['index']\n",
        "      gold_entities = validation_dataset[idx]['entities']\n",
        "      # flatten gold mentions: (mention_text, type)\n",
        "      gold_set = set()\n",
        "      for ent in gold_entities:\n",
        "          for m in ent['mentions']:\n",
        "              gold_set.add((m, ent['type']))\n",
        "      # flatten predicted mentions: pipeline outputs 'word' and 'entity_group'\n",
        "      pred_list = pred['predictions']\n",
        "      pred_set = set()\n",
        "      for p in pred_list:\n",
        "          w = p.get('word')\n",
        "          et = p.get('entity_group')\n",
        "          pred_set.add((w, et))\n",
        "      # Append to global lists\n",
        "      all_gold.append(gold_set)\n",
        "      all_pred.append(pred_set)\n",
        "\n",
        "  # Compute micro-level counts\n",
        "  tp = 0\n",
        "  pred_count = 0\n",
        "  gold_count = 0\n",
        "  for gold_set, pred_set in zip(all_gold, all_pred):\n",
        "      tp += len(gold_set & pred_set)\n",
        "      pred_count += len(pred_set)\n",
        "      gold_count += len(gold_set)\n",
        "\n",
        "  precision = tp / pred_count if pred_count > 0 else 0.0\n",
        "  recall = tp / gold_count if gold_count > 0 else 0.0\n",
        "  f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "  # Print and save metrics\n",
        "  metrics = {\n",
        "      'precision': precision,\n",
        "      'recall': recall,\n",
        "      'f1': f1,\n",
        "      'true_positives': tp,\n",
        "      'predicted': pred_count,\n",
        "      'gold': gold_count\n",
        "  }\n",
        "  print(\"NER Validation Mention-level Metrics:\")\n",
        "  print(metrics)\n",
        "\n",
        "  # Save metrics to JSON\n",
        "  with open(output_path, 'w') as f:\n",
        "      json.dump(metrics, f, indent=2)\n",
        "  print(f\"Saved evaluation metrics to {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3281bd74",
      "metadata": {
        "id": "3281bd74"
      },
      "source": [
        "# Load data into Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a156e72",
      "metadata": {
        "id": "9a156e72"
      },
      "outputs": [],
      "source": [
        "# Load JSON files and store them in memory\n",
        "aggregated_data = []\n",
        "folder_path = f'{base_path}raw/train'\n",
        "\n",
        "# loop through all files in the given folder\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "    for file_name in files:\n",
        "        with open(f\"{folder_path}/{file_name}\", \"r\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        for d in data:\n",
        "          aggregated_data.append(d)\n",
        "\n",
        "dataset = Dataset.from_list(aggregated_data)\n",
        "print(\"Sample example:\")\n",
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f46f4dd",
      "metadata": {
        "id": "9f46f4dd"
      },
      "source": [
        "# Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e5bfbcf",
      "metadata": {
        "id": "9e5bfbcf"
      },
      "outputs": [],
      "source": [
        "model_name = 'allenai/longformer-base-4096'\n",
        "\n",
        "# Prepare label mappings\n",
        "entity_labels = dataset[0]['entity_label_set']  # list of entity types\n",
        "label_list = ['O'] + [f\"B-{l}\" for l in entity_labels] + [f\"I-{l}\" for l in entity_labels]\n",
        "print(label_list)\n",
        "label2id = {l: i for i, l in enumerate(label_list)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "\n",
        "# Tokenizer and model init\n",
        "tokenizer = LongformerTokenizerFast.from_pretrained(\n",
        "    model_name,\n",
        "    max_length = max_token_length\n",
        ")\n",
        "\n",
        "model = LongformerForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4bbd478",
      "metadata": {
        "id": "a4bbd478"
      },
      "source": [
        "# Split Data into Validation and Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fb49594",
      "metadata": {
        "id": "4fb49594"
      },
      "outputs": [],
      "source": [
        "# Function to tokenize and align labels\n",
        "trunc_count = 0\n",
        "\n",
        "whitespace = re.compile(r\"\\s\")\n",
        "\n",
        "def is_word_start(text: str, char_idx: int) -> bool:\n",
        "    \"\"\"\n",
        "    Heuristic: a character is the start of a word if it is at position 0\n",
        "    or the previous character is any whitespace.\n",
        "    Works well for normal prose tokenised with a BPE WordPiece tokenizer.\n",
        "    \"\"\"\n",
        "    return char_idx == 0 or bool(whitespace.match(text[char_idx - 1]))\n",
        "\n",
        "def tokenize_and_align_labels(example: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    • Pads / truncates to `max_token_length`.\n",
        "    • Sets label = -100 on:\n",
        "        – special tokens ([CLS], [SEP], etc.)\n",
        "        – all sub-tokens *except* the first piece of each word\n",
        "        – all padding tokens\n",
        "    • Emits exactly one label per word, using your B-/I- scheme.\n",
        "    \"\"\"\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        example[\"doc\"],\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_token_length,\n",
        "    )\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 1. Init every position with ignore_index (-100)\n",
        "    # ------------------------------------------------------------------\n",
        "    labels = [-100] * len(encoding[\"input_ids\"])\n",
        "    doc_text = example[\"doc\"]\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 2. Mark the first sub-token of every *word* as O\n",
        "    # ------------------------------------------------------------------\n",
        "    for idx, (off_start, off_end) in enumerate(encoding[\"offset_mapping\"]):\n",
        "        if off_start == off_end:          # special tokens → keep -100\n",
        "            continue\n",
        "        if is_word_start(doc_text, off_start):\n",
        "            labels[idx] = label2id[\"O\"]   # will be overwritten if it is an entity\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 3. Overwrite labels for entity mentions\n",
        "    # ------------------------------------------------------------------\n",
        "    for ent in example[\"entities\"]:\n",
        "        ent_type = ent[\"type\"]            # e.g. \"PERSON\"\n",
        "        for m_text in ent[\"mentions\"]:\n",
        "            for match in re.finditer(re.escape(m_text), doc_text):\n",
        "                start_char, end_char = match.start(), match.end()\n",
        "\n",
        "                for idx, (off_start, off_end) in enumerate(encoding[\"offset_mapping\"]):\n",
        "                    if off_start >= start_char and off_end <= end_char:\n",
        "                        if off_start == start_char:\n",
        "                            labels[idx] = label2id[f\"B-{ent_type}\"]\n",
        "                        elif is_word_start(doc_text, off_start):\n",
        "                            labels[idx] = label2id[f\"I-{ent_type}\"]\n",
        "                        # every other sub-token stays -100\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 4. Remove the offsets (Trainer doesn’t need them) and attach labels\n",
        "    # ------------------------------------------------------------------\n",
        "    encoding.pop(\"offset_mapping\")\n",
        "    encoding[\"labels\"] = labels\n",
        "    return encoding\n",
        "\n",
        "# Split original dataset into train and validation (preserve raw columns)\n",
        "all_indices = list(range(len(dataset)))\n",
        "train_idx, val_idx = train_test_split(all_indices, test_size=0.1, random_state=42)\n",
        "train_orig = dataset.select(train_idx)\n",
        "val_orig = dataset.select(val_idx)\n",
        "print(f\"Original train size: {len(train_orig)}, validation size: {len(val_orig)}\")\n",
        "\n",
        "# Tokenize & align labels separately, removing raw columns only from tokenized sets\n",
        "train_tok = train_orig.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=False,\n",
        "    remove_columns=['domain','title','doc','triples','entities','label_set','entity_label_set']\n",
        ")\n",
        "val_tok = val_orig.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=False,\n",
        "    remove_columns=['domain','title','doc','triples','entities','label_set','entity_label_set']\n",
        ")\n",
        "print(f\"Documents truncated in training: {trunc_count} / {len(train_tok)}\")\n",
        "\n",
        "# Use tokenized datasets for training and evaluation\n",
        "train_ds = train_tok\n",
        "val_ds = val_tok\n",
        "print(f\"Train set size: {len(train_ds)}, Validation set size: {len(val_ds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f7d0c48",
      "metadata": {
        "id": "1f7d0c48"
      },
      "source": [
        "# Baseline NER with Untrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "025d714b",
      "metadata": {
        "id": "025d714b"
      },
      "outputs": [],
      "source": [
        "# Create NER pipeline using the fine-tuned model\n",
        "ner_pipe_untrained = pipeline(\n",
        "    'ner',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0,\n",
        "    aggregation_strategy='simple'\n",
        ")\n",
        "\n",
        "# Run NER on validation documents and collect aggregated results\n",
        "val_results = []\n",
        "for idx, example in enumerate(val_orig):\n",
        "    preds = ner_pipe_untrained(example['doc'])\n",
        "    val_results.append({\n",
        "        'index': idx,\n",
        "        'doc_title': example.get('title', f'doc_{idx}'),\n",
        "        'predictions': preds\n",
        "    })\n",
        "\n",
        "# Save to JSON in Google Drive folder\n",
        "output_path = f'{base_path}processed/ner_untrained_predictions.json'\n",
        "save_model_output(val_results, output_path)\n",
        "\n",
        "scores_path = f'{base_path}processed/ner_untrained_scores.json'\n",
        "compute_f1(output_path, scores_path, val_orig)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "569023bb",
      "metadata": {
        "id": "569023bb"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_safe_weights(\n",
        "    train_dataset: Dataset,\n",
        "    label_column: str = \"labels\",\n",
        "    o_label_id: int = 0,\n",
        "    clip_range: tuple = (0.05, 5.0),\n",
        "    o_label_weight: float = 0.10,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Build a class-weight tensor for token-level NER that\n",
        "\n",
        "    1. is inverse-frequency based (rare labels ↑ weight);\n",
        "    2. has mean weight = 1 (keeps the overall loss scale stable);\n",
        "    3. is clipped to `clip_range` to avoid huge gradients;\n",
        "    4. overwrites the 'O' label weight with `o_label_weight`.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_dataset : datasets.Dataset\n",
        "        Your training split after any `-100` masking.\n",
        "    label_column : str\n",
        "        Column that holds the integer tag sequences.\n",
        "    o_label_id : int\n",
        "        ID of the majority 'O' label (usually 0).\n",
        "    clip_range : (float, float)\n",
        "        Min / max weight allowed after normalisation.\n",
        "    o_label_weight : float\n",
        "        Final weight assigned to the 'O' label.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor  shape = (num_labels,)\n",
        "    \"\"\"\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Count how many *labelled* tokens of each class you have\n",
        "    # ------------------------------------------------------------------\n",
        "    counts: Counter[int] = Counter()\n",
        "    for seq in train_dataset[label_column]:\n",
        "        for lbl in seq:\n",
        "            if lbl != -100:          # ignore the sub-token masks\n",
        "                counts[lbl] += 1\n",
        "\n",
        "    num_labels = max(counts) + 1     # assumes label ids are 0 … N-1\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Inverse-frequency weighting\n",
        "    # ------------------------------------------------------------------\n",
        "    total = sum(counts.values())\n",
        "    inv_freq = {lbl: total / cnt for lbl, cnt in counts.items()}\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Normalise so that mean(weight)=1, then clip\n",
        "    # ------------------------------------------------------------------\n",
        "    mean_w = sum(inv_freq.values()) / len(inv_freq)\n",
        "    weights = {}\n",
        "    low, high = clip_range\n",
        "    for lbl in range(num_labels):\n",
        "        w = inv_freq.get(lbl, 1.0) / mean_w     # unseen lbls → weight 1\n",
        "        w = max(low, min(w, high))              # clip to safe range\n",
        "        weights[lbl] = w\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Down-weight the 'O' label explicitly\n",
        "    # ------------------------------------------------------------------\n",
        "    weights[o_label_id] = o_label_weight\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Build tensor\n",
        "    # ------------------------------------------------------------------\n",
        "    weight_vector = torch.tensor(\n",
        "        [weights[i] for i in range(num_labels)],\n",
        "        dtype=torch.float32\n",
        "    )\n",
        "\n",
        "    return weight_vector"
      ],
      "metadata": {
        "id": "y4WEIL8GRv9e"
      },
      "id": "y4WEIL8GRv9e",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightedTrainer(Trainer):\n",
        "    def __init__(self, *args, loss_weights=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_weights = loss_weights\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = CrossEntropyLoss(\n",
        "            weight=self.loss_weights.to(model.device),\n",
        "            ignore_index=-100\n",
        "        )\n",
        "        # reshape to (batch_size*seq_len, num_labels)\n",
        "        loss = loss_fct(\n",
        "            logits.view(-1, model.config.num_labels),\n",
        "            labels.view(-1)\n",
        "        )\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "0w6n4GDR3ypC"
      },
      "id": "0w6n4GDR3ypC",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "b9b30c2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9b30c2f",
        "outputId": "42d1b32a-bc94-47a7-ab35-57ff4276a7ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using learning_rate=1e-05, batch_size=2, epochs=5, warmup_steps=30, weight_decay=0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-56ae36a60d36>:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Training arguments\n",
        "train_batch_size = 2\n",
        "gradient_accumulation_steps = 8\n",
        "num_epochs = 5\n",
        "learning_rate = 1e-5\n",
        "total_steps = math.ceil(len(train_ds) / train_batch_size / gradient_accumulation_steps) * num_epochs\n",
        "warmup_steps = int(total_steps * 0.1)\n",
        "weight_vector = make_safe_weights(train_ds)\n",
        "print(f\"Using learning_rate={learning_rate}, batch_size={train_batch_size}, epochs={num_epochs}, warmup_steps={warmup_steps}, weight_decay=0.01\")\n",
        "\n",
        "\"\"\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./models/longformer-ner',\n",
        "    num_train_epochs=num_epochs,\n",
        "    learning_rate=learning_rate,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    per_device_train_batch_size=train_batch_size,\n",
        "    per_device_eval_batch_size=train_batch_size,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=0.01,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,\n",
        "    save_total_limit=2,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1'\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./models/longformer-ner-hp',\n",
        "    num_train_epochs=num_epochs,\n",
        "    learning_rate=learning_rate,\n",
        "    lr_scheduler_type='linear',\n",
        "    warmup_ratio=0.2,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=0.01,\n",
        "    max_grad_norm=1.0,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    save_steps=1000,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1',\n",
        "    greater_is_better=True,\n",
        "    fp16=True,\n",
        "\n",
        ")\n",
        "\n",
        "# Metric computation\n",
        "evaluator = evaluate.load('seqeval')\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    preds = predictions.argmax(-1)\n",
        "    true_labels = [[id2label[l] for l in label_seq if l != -100] for label_seq in labels]\n",
        "    true_preds = [[id2label[p_] for (p_, l) in zip(pred_seq, label_seq) if l != -100]\n",
        "                  for pred_seq, label_seq in zip(preds, labels)]\n",
        "    results = evaluator.compute(predictions=true_preds, references=true_labels)\n",
        "    return {\n",
        "        'precision': results['overall_precision'],\n",
        "        'recall': results['overall_recall'],\n",
        "        'f1': results['overall_f1']\n",
        "    }\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    loss_weights=weight_vector,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(weight_vector)"
      ],
      "metadata": {
        "id": "JWCYFUC9Qg3r",
        "outputId": "14d19d23-ad6a-4515-d0c1-162ef7b63339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JWCYFUC9Qg3r",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1000, 0.0500, 0.0500, 1.9211, 1.3049, 0.0500, 5.0000, 0.0500, 1.2575,\n",
            "        0.4405, 0.0500, 0.0637, 0.0500, 0.4269, 0.0500, 0.6916, 1.2350, 4.9401,\n",
            "        0.5716, 0.0500, 0.2640, 0.0850, 0.7130, 0.7950, 0.1383, 5.0000, 0.8755,\n",
            "        0.9741, 0.1462, 0.3047, 2.0958, 0.0500, 0.1695, 0.0597, 0.5320, 0.5812,\n",
            "        3.6400, 0.2203, 0.0500])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "\n",
        "print(f\"Total truncated documents: {trunc_count} / {len(dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "YOGKCutIGFU4",
        "outputId": "2f1f1a26-edf7-4515-ad38-b195b7ba52ea"
      },
      "id": "YOGKCutIGFU4",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='209' max='295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [209/295 08:18 < 03:27, 0.42 it/s, Epoch 3.47/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.998394</td>\n",
              "      <td>0.017717</td>\n",
              "      <td>0.002634</td>\n",
              "      <td>0.004586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.149300</td>\n",
              "      <td>0.963859</td>\n",
              "      <td>0.018194</td>\n",
              "      <td>0.002685</td>\n",
              "      <td>0.004679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.149300</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-63a3bfbe6c37>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total truncated documents: {trunc_count} / {len(dataset)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2558\u001b[0m                     )\n\u001b[1;32m   2559\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2560\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m                     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3780\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale_wrt_gas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3782\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3784\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2448\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2450\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2451\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca63db25",
      "metadata": {
        "id": "ca63db25"
      },
      "source": [
        "# NER on Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d6e97528",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6e97528",
        "outputId": "0b4152ee-0d76-4fd0-82e7-1bd660191f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Input ids are automatically padded to be a multiple of `config.attention_window`: 512\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved validation NER predictions to drive/MyDrive/dataset/processed/ner_trained_predictions.json\n",
            "NER Validation Mention-level Metrics:\n",
            "{'precision': 0.0016970725498515061, 'recall': 0.007380073800738007, 'f1': 0.0027595722662987236, 'true_positives': 4, 'predicted': 2357, 'gold': 542}\n",
            "Saved evaluation metrics to drive/MyDrive/dataset/processed/ner_trained_scores.json\n"
          ]
        }
      ],
      "source": [
        "# Create NER pipeline using the fine-tuned model\n",
        "ner_pipe_finetuned = pipeline(\n",
        "    'ner',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0,\n",
        "    aggregation_strategy='simple'\n",
        ")\n",
        "\n",
        "# Run NER on validation documents and collect aggregated results\n",
        "val_results = []\n",
        "for idx, example in enumerate(val_orig):\n",
        "    preds = ner_pipe_finetuned(example['doc'])\n",
        "    val_results.append({\n",
        "        'index': idx,\n",
        "        #'doc_title': example.get('title', f'doc_{idx}'),\n",
        "        'predictions': preds\n",
        "    })\n",
        "\n",
        "# Save to JSON in Google Drive folder\n",
        "output_path = f'{base_path}processed/ner_trained_predictions.json'\n",
        "save_model_output(val_results, output_path)\n",
        "\n",
        "scores_path = f'{base_path}processed/ner_trained_scores.json'\n",
        "compute_f1(output_path, scores_path, val_orig)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.save_to_disk(f'{base_path}processed/train_ds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1d4ce6e59399448eb30f99608c8577af",
            "f0d34297d0b7435599991db36e50558b",
            "c157931b748247abb27562ada9a43d6e",
            "373db45ed27b4cda987c1e0c5466f09a",
            "cb770c56115944cda024f0e258efa95a",
            "23b95b0fed7d442d963dbcda0c2988e1",
            "1046a2b3bde8442ea8593d087e04cfcb",
            "890f534fe6e840a2a1b4de75a36052c6",
            "c5e211a1011b4c519c0f9e086892200d",
            "2ec435f183ff421fa86cac0217c3f689",
            "978469a5fe28478cb5bf45a06ca28d2e"
          ]
        },
        "id": "n-qcvU47VvfK",
        "outputId": "b2d320d2-763c-4ac7-b45a-909c94b7678c"
      },
      "id": "n-qcvU47VvfK",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/945 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d4ce6e59399448eb30f99608c8577af"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d4ce6e59399448eb30f99608c8577af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0d34297d0b7435599991db36e50558b",
              "IPY_MODEL_c157931b748247abb27562ada9a43d6e",
              "IPY_MODEL_373db45ed27b4cda987c1e0c5466f09a"
            ],
            "layout": "IPY_MODEL_cb770c56115944cda024f0e258efa95a"
          }
        },
        "f0d34297d0b7435599991db36e50558b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23b95b0fed7d442d963dbcda0c2988e1",
            "placeholder": "​",
            "style": "IPY_MODEL_1046a2b3bde8442ea8593d087e04cfcb",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "c157931b748247abb27562ada9a43d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_890f534fe6e840a2a1b4de75a36052c6",
            "max": 945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5e211a1011b4c519c0f9e086892200d",
            "value": 945
          }
        },
        "373db45ed27b4cda987c1e0c5466f09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ec435f183ff421fa86cac0217c3f689",
            "placeholder": "​",
            "style": "IPY_MODEL_978469a5fe28478cb5bf45a06ca28d2e",
            "value": " 945/945 [00:00&lt;00:00, 26204.69 examples/s]"
          }
        },
        "cb770c56115944cda024f0e258efa95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23b95b0fed7d442d963dbcda0c2988e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1046a2b3bde8442ea8593d087e04cfcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "890f534fe6e840a2a1b4de75a36052c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5e211a1011b4c519c0f9e086892200d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ec435f183ff421fa86cac0217c3f689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "978469a5fe28478cb5bf45a06ca28d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}