{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "300eb73b",
      "metadata": {
        "id": "300eb73b"
      },
      "source": [
        "# Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a9273274",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9273274",
        "outputId": "3c177074-225d-4c8d-d1d8-9af9b880005a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets torch seqeval evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff5f51e5",
      "metadata": {
        "id": "ff5f51e5"
      },
      "source": [
        "# Env Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5558fb9a",
      "metadata": {
        "id": "5558fb9a"
      },
      "outputs": [],
      "source": [
        "base_path = 'data/'\n",
        "max_token_length = 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53def38a",
      "metadata": {
        "id": "53def38a"
      },
      "source": [
        "# Establish Google Drive Connection (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "785ce452",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "785ce452",
        "outputId": "aa33bf92-f7de-4784-bab0-93a738fe0e3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_path = 'drive/MyDrive/dataset/'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4192d65",
      "metadata": {
        "id": "b4192d65"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "205b781e",
      "metadata": {
        "id": "205b781e"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    LongformerTokenizerFast,\n",
        "    LongformerForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    pipeline,\n",
        "    TrainerCallback,\n",
        "    TrainerState,\n",
        "    TrainerControl\n",
        ")\n",
        "import evaluate\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a32ad725",
      "metadata": {
        "id": "a32ad725"
      },
      "source": [
        "# Helper Functions\n",
        "\n",
        "## Load Data\n",
        "Loads all json files in a specified path and combines them in one aggregated list\n",
        "\n",
        "## Convert Numpy Floats\n",
        "\n",
        "## Save Model Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "31d8299a",
      "metadata": {
        "id": "31d8299a"
      },
      "outputs": [],
      "source": [
        "def load_json_data(folder_path):\n",
        "    aggregated_data = []\n",
        "\n",
        "    # loop through all files in the given folder\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file_name in files:\n",
        "            with open(f\"{folder_path}/{file_name}\", \"r\") as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            aggregated_data.append(data)\n",
        "\n",
        "    return aggregated_data\n",
        "\n",
        "# Convert NumPy float32 to native Python floats before JSON serialization\n",
        "def convert_numpy_floats(obj):\n",
        "    if isinstance(obj, np.float32):\n",
        "        return float(obj)\n",
        "    raise TypeError\n",
        "\n",
        "def save_model_output(output, output_path):\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(output, f, ensure_ascii=False, indent=2, default=convert_numpy_floats)\n",
        "    print(f\"Saved validation NER predictions to {output_path}\")\n",
        "\n",
        "def compute_f1(predictions_file_path, output_path, validation_dataset):\n",
        "  # Load saved predictions\n",
        "  with open(predictions_file_path, 'r') as f:\n",
        "      saved_preds = json.load(f)\n",
        "\n",
        "  # Prepare gold and predicted lists\n",
        "  all_gold = []\n",
        "  all_pred = []\n",
        "  for pred in saved_preds:\n",
        "      idx = pred['index']\n",
        "      gold_entities = validation_dataset[idx]['entities']\n",
        "      # flatten gold mentions: (mention_text, type)\n",
        "      gold_set = set()\n",
        "      for ent in gold_entities:\n",
        "          for m in ent['mentions']:\n",
        "              gold_set.add((m, ent['type']))\n",
        "      # flatten predicted mentions: pipeline outputs 'word' and 'entity_group'\n",
        "      pred_list = pred['predictions']\n",
        "      pred_set = set()\n",
        "      for p in pred_list:\n",
        "          w = p.get('word')\n",
        "          et = p.get('entity_group')\n",
        "          pred_set.add((w, et))\n",
        "      # Append to global lists\n",
        "      all_gold.append(gold_set)\n",
        "      all_pred.append(pred_set)\n",
        "\n",
        "  # Compute micro-level counts\n",
        "  tp = 0\n",
        "  pred_count = 0\n",
        "  gold_count = 0\n",
        "  for gold_set, pred_set in zip(all_gold, all_pred):\n",
        "      tp += len(gold_set & pred_set)\n",
        "      pred_count += len(pred_set)\n",
        "      gold_count += len(gold_set)\n",
        "\n",
        "  precision = tp / pred_count if pred_count > 0 else 0.0\n",
        "  recall = tp / gold_count if gold_count > 0 else 0.0\n",
        "  f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "  # Print and save metrics\n",
        "  metrics = {\n",
        "      'precision': precision,\n",
        "      'recall': recall,\n",
        "      'f1': f1,\n",
        "      'true_positives': tp,\n",
        "      'predicted': pred_count,\n",
        "      'gold': gold_count\n",
        "  }\n",
        "  print(\"NER Validation Mention-level Metrics:\")\n",
        "  print(metrics)\n",
        "\n",
        "  # Save metrics to JSON\n",
        "  with open(output_path, 'w') as f:\n",
        "      json.dump(metrics, f, indent=2)\n",
        "  print(f\"Saved evaluation metrics to {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3281bd74",
      "metadata": {
        "id": "3281bd74"
      },
      "source": [
        "# Load data into Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9a156e72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a156e72",
        "outputId": "e4cd83f1-a876-4626-afe7-e964e6e4d495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample example:\n",
            "{'domain': 'Energy', 'title': 'Advanced_thermal_recycling_system', 'doc': 'An advanced thermal recycling system (or an ATR system) is the commercial brand name of the waste-to-energy incineration offering by Klean Power, which has been implemented in a single plant in Germany in 1999. WtE facilities such as the ATR transforms municipal solid waste (MSW) into electricity or steam for district heating or industrial customers. The combustion bottom ash, and the combustion fly ash, along with the air pollution control system fly ash, are treated to produce products that can be beneficially reused. Specifically, ATR systems consist of the following:\\nSolid waste combustion, boiler and combustion control system, energy recovery and air pollution control equipment;\\nCombustion bottom ash and fly ash treatment systems that produce commercially reusable products; and\\nAn optional pre-processing system to recover recyclable materials contained in the MSW delivered to the facility before the MSW enters the thermal processing area of the facility.\\nOne commercially operating ATR facility has been built so far. It is the Müllverwertung Rugenberger Damm WtE plant in Hamburg, Germany, commissioned in 1999. The German Green Party has endorsed the specific features of this facility in its \"Concept 2020\" initiative to cease all landfilling of waste by 2020 as an essential part of an integrated waste management system achieving the highest standards in the energy-from-waste industry. No landfilling of unprocessed waste has been allowed in Germany since 2005.Overhead refuse cranes are used to hold approximately five tons of garbage each. The waste is then mixed in the bunker to create a homogeneous mixture to ensure that the bottom ash byproduct has good combustion, and low carbon content. These cranes then deliver the mixed waste into the feeding hopper, which leads down onto stoker grates. These grates control the rate at which the waste travels through the boiler. The heat ignites the trash as it moves along the forward feeding grates until only the byproduct bottom ash remains at the end of the grate. Each combustion line feeds a boiler that operates above 1,560 °F (850 °C) for two seconds. The temperature in the combustion zone is measured through acoustic monitoring. A computer controls the temperature, the grate speed, the amount of air used, and all other aspects of the process that enable complete combustion and minimization of emissions.\\nMaintaining the furnace\\'s high temperature is essential to rid the waste and the resulting combustion gases of complex organic compounds such as dioxins and furans. To prevent the reformulation of pollutants, fly ash is separated from the flue gas downstream of the superheaters to reduce the fly ash content, which could act as a catalyst in the critical reformulation temperature range of 600 to 400 °F (316 to 204 °C). At the exit of the boiler, the flue gas is cooled down to a level of 340 °F (171 °C).\\nAs the waste is combusted, heat is released in the boiler. This heat produces high-pressure, high-temperature steam, which generates electrical energy when passed through a turbine generator. The electricity is fed into the public power grid or sold directly to a customer. The steam can also be exported directly for use in district heating or industrial processes.\\nEach unit has an independent air pollution control system. Flue gas cleaning begins in the boiler, where oxides of nitrogen are reduced by injecting ammonia water into the combustion chamber. Lightly loaded absorbents (activated carbon from the second bag house) are injected into the flue gas downstream of the first bag house to separate any contaminants that have reformed (such as organic compounds), any condensed heavy metals, salts and other gaseous contaminants, as well as residue fly ash.\\nThe first baghouse makes it possible to produce reusable by-products such as hydrochloric acid and gypsum from the consecutive air pollution control process steps. Acid gases are removed from the flue gases by passing through a two-stage scrubber to remove acid components, especially halogen compounds such as hydrochloric acid and hydrofluoric acid. A counter-flow neutral scrubber follows, using a lime slurry to remove sulphur oxides. The pollutant gases are either dissolved in water droplets (acids) or bound as calcium salts and thereby removed from the flue gas. A second baghouse acts as a polishing filter to capture any remaining aerosols, organic compounds and heavy metals, which thereby are reduced to levels usually below detection.\\nFollowing combustion, the material left consists of the non-combustible components of the waste and the inert materials produced during combustion. This is known as bottom ash. The bottom ash is washed to eliminate soluble salts. Iron scrap and non-ferrous metals such as aluminium, copper and brass are separated and sold in secondary metals markets. The bottom ash is then screened, crushed and sold for use as a construction material.\\nGypsum is created when the oxides of sulphur (SO2 and SO3) are separated by the single stage scrubber. It is purified, then sold to the construction industry.\\nThe acid scrubbing process in the flue gas treatment system also produces a raw hydrochloric acid at a concentration of 10% to 12%. The acid is distilled (rectified) to yield commercial-grade (30% concentration) hydrochloric acid.\\nFly ash, separated in the boiler and baghouses and constituting up to 5% by weight of the combusted MSW, is treated to recover metals and minerals for reuse, resulting in an overall ATR process landfill diversion rate of approximately 98.5%.\\n', 'entities': [{'id': 0, 'mentions': ['Müllverwertung Rugenberger Damm WtE plant', 'ATR systems', 'ATR system', 'ATR facility', 'advanced thermal recycling system'], 'type': 'PRODUCT'}, {'id': 1, 'mentions': ['Klean Power'], 'type': 'ORG'}, {'id': 2, 'mentions': ['Germany'], 'type': 'GPE'}, {'id': 3, 'mentions': ['1999'], 'type': 'DATE'}, {'id': 4, 'mentions': ['unprocessed waste', 'waste', 'MSW', 'garbage', 'municipal solid waste', 'mixed waste', 'landfilling of waste'], 'type': 'PRODUCT'}, {'id': 5, 'mentions': ['One'], 'type': 'CARDINAL'}, {'id': 6, 'mentions': ['Hamburg', 'Hamburg, Germany'], 'type': 'GPE'}, {'id': 7, 'mentions': ['German Green Party'], 'type': 'ORG'}, {'id': 8, 'mentions': ['2020'], 'type': 'DATE'}, {'id': 9, 'mentions': ['approximately five tons'], 'type': 'QUANTITY'}, {'id': 10, 'mentions': ['1,560 °'], 'type': 'QUANTITY'}, {'id': 11, 'mentions': ['850'], 'type': 'QUANTITY'}, {'id': 12, 'mentions': ['two seconds'], 'type': 'TIME'}, {'id': 13, 'mentions': ['600'], 'type': 'QUANTITY'}, {'id': 14, 'mentions': ['316'], 'type': 'QUANTITY'}, {'id': 15, 'mentions': ['204'], 'type': 'QUANTITY'}, {'id': 16, 'mentions': ['340'], 'type': 'QUANTITY'}, {'id': 17, 'mentions': ['second'], 'type': 'TIME'}, {'id': 18, 'mentions': ['first'], 'type': 'ORDINAL'}, {'id': 19, 'mentions': ['Gypsum', 'gypsum'], 'type': 'PRODUCT'}, {'id': 20, 'mentions': ['10% to 12%'], 'type': 'PERCENT'}, {'id': 21, 'mentions': ['30%'], 'type': 'PERCENT'}, {'id': 22, 'mentions': ['up to 5%'], 'type': 'PERCENT'}, {'id': 23, 'mentions': ['approximately 98.5%'], 'type': 'PERCENT'}, {'id': 24, 'mentions': ['combustion bottom ash', 'Combustion bottom ash', 'bottom ash'], 'type': 'MISC'}, {'id': 25, 'mentions': ['Fly ash', 'combustion fly ash', 'residue fly ash', 'fly ash'], 'type': 'MISC'}, {'id': 26, 'mentions': ['high-pressure, high-temperature steam'], 'type': 'MISC'}, {'id': 27, 'mentions': ['electrical energy'], 'type': 'MISC'}, {'id': 28, 'mentions': ['public power grid'], 'type': 'PRODUCT'}, {'id': 29, 'mentions': ['hydrochloric acid'], 'type': 'MISC'}, {'id': 30, 'mentions': ['two-stage scrubber'], 'type': 'PRODUCT'}, {'id': 31, 'mentions': ['acid scrubbing process', 'acid scrubbing process in the flue gas treatment system'], 'type': 'MISC'}], 'triples': [{'head': 'Klean Power', 'relation': 'OwnerOf', 'tail': 'advanced thermal recycling system'}, {'head': 'Müllverwertung Rugenberger Damm WtE plant', 'relation': 'LocatedIn', 'tail': 'Hamburg, Germany'}, {'head': 'advanced thermal recycling system', 'relation': 'SaidToBeTheSameAs', 'tail': 'waste-to-energy incineration offering'}, {'head': 'Müllverwertung Rugenberger Damm WtE plant', 'relation': 'LocatedIn', 'tail': 'Hamburg, Germany'}], 'label_set': ['Promoted', 'Replaces', 'Partner', 'NominatedFor', 'InterestedIn', 'NamedAfter', 'HasPart', 'SignificantEvent', 'MemberOf', 'InfluencedBy', 'ContainsAdministrativeTerritorialEntity', 'InOppositionTo', 'Country', 'SaidToBeTheSameAs', 'WorkLocation', 'DifferentFrom', 'LocatedIn', 'HasWorksInTheCollection', 'PartOf', 'Creator', 'AcademicDegree', 'UsedBy', 'EducatedAt', 'CountryOfCitizenship', 'Author', 'DiplomaticRelation', 'OwnerOf', 'Follows', 'FollowedBy', 'OwnedBy'], 'entity_label_set': ['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART', 'MISC']}\n"
          ]
        }
      ],
      "source": [
        "# Load JSON files and store them in memory\n",
        "aggregated_data = []\n",
        "folder_path = f'{base_path}raw/train'\n",
        "\n",
        "# loop through all files in the given folder\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "    for file_name in files:\n",
        "        with open(f\"{folder_path}/{file_name}\", \"r\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        for d in data:\n",
        "          aggregated_data.append(d)\n",
        "\n",
        "dataset = Dataset.from_list(aggregated_data)\n",
        "print(\"Sample example:\")\n",
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f46f4dd",
      "metadata": {
        "id": "9f46f4dd"
      },
      "source": [
        "# Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9e5bfbcf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e5bfbcf",
        "outputId": "2792ef55-8f66-497b-eba0-92bf4bdf7ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'B-CARDINAL', 'B-DATE', 'B-EVENT', 'B-FAC', 'B-GPE', 'B-LANGUAGE', 'B-LAW', 'B-LOC', 'B-MONEY', 'B-NORP', 'B-ORDINAL', 'B-ORG', 'B-PERCENT', 'B-PERSON', 'B-PRODUCT', 'B-QUANTITY', 'B-TIME', 'B-WORK_OF_ART', 'B-MISC', 'I-CARDINAL', 'I-DATE', 'I-EVENT', 'I-FAC', 'I-GPE', 'I-LANGUAGE', 'I-LAW', 'I-LOC', 'I-MONEY', 'I-NORP', 'I-ORDINAL', 'I-ORG', 'I-PERCENT', 'I-PERSON', 'I-PRODUCT', 'I-QUANTITY', 'I-TIME', 'I-WORK_OF_ART', 'I-MISC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LongformerForTokenClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_name = 'allenai/longformer-base-4096'\n",
        "\n",
        "# Prepare label mappings\n",
        "entity_labels = dataset[0]['entity_label_set']  # list of entity types\n",
        "label_list = ['O'] + [f\"B-{l}\" for l in entity_labels] + [f\"I-{l}\" for l in entity_labels]\n",
        "print(label_list)\n",
        "label2id = {l: i for i, l in enumerate(label_list)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "\n",
        "# Tokenizer and model init\n",
        "tokenizer = LongformerTokenizerFast.from_pretrained(\n",
        "    model_name,\n",
        "    max_length = max_token_length\n",
        ")\n",
        "\n",
        "model = LongformerForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4bbd478",
      "metadata": {
        "id": "a4bbd478"
      },
      "source": [
        "# Split Data into Validation and Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4fb49594",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "802642f6f9324572a46462469b17c2cd",
            "d263c6f3bef7483da602a1030ec36245",
            "6ad22ddb7189453c953935408c8798af",
            "f8d0e89b1a6b4118a66f847bab5cc546",
            "62e99c1bd15344c6b179764657fee6f4",
            "20625b1874bf4164bf046fe4534e64b3",
            "de2df7a9eb114d2ab6947a7f2222eec3",
            "c32a482eec014343ab8abc9063cfd57b",
            "f9090c82ae404298af0a61b1cce426ce",
            "64aaa6ddbf4a460e9f91128db7562023",
            "94481d1049704319ac804d7966683dad",
            "566903f7ee8f4ae7a240f779f2b15dc8",
            "82645ad12cd7479d90be0fab7c0610af",
            "8e31ead02b514327aad3ddecc2af9b42",
            "843712ac4d5043d48326852cf93b32b3",
            "7bd420efc4be4266bda94e889c2701d2",
            "364595c4ba24420ba32ab2ea31dfb03c",
            "28a61c0f858f414e95251022fd46c5b9",
            "31edae985ea2481da76f60d14aabe5d6",
            "e0371e9c862d486fa9843d62ee1baebc",
            "27c5560addef48f78318f7cc39b22ec1",
            "5292582c4ecf4bb0ac6f62209fb8c631"
          ]
        },
        "id": "4fb49594",
        "outputId": "ae0fd087-bd0e-42ed-a995-e5f56056dca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original train size: 135, validation size: 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/135 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "802642f6f9324572a46462469b17c2cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "566903f7ee8f4ae7a240f779f2b15dc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents truncated in training: 151 / 135\n",
            "Train set size: 135, Validation set size: 16\n"
          ]
        }
      ],
      "source": [
        "# Function to tokenize and align labels\n",
        "trunc_count = 0\n",
        "\n",
        "def tokenize_and_align_labels(example):\n",
        "    global trunc_count\n",
        "    encoding = tokenizer(\n",
        "        example['doc'],\n",
        "        return_offsets_mapping=True,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=max_token_length\n",
        "    )\n",
        "    if len(encoding['input_ids']) == max_token_length:\n",
        "        trunc_count += 1\n",
        "    labels = [label2id['O']] * len(encoding['input_ids'])\n",
        "    doc_text = example['doc']\n",
        "    for ent in example['entities']:\n",
        "        ent_type = ent['type']\n",
        "        for m_text in ent['mentions']:\n",
        "            # find all occurrences of mention string\n",
        "            for match in re.finditer(re.escape(m_text), doc_text):\n",
        "                start_char, end_char = match.start(), match.end()\n",
        "                for idx, (off_start, off_end) in enumerate(encoding['offset_mapping']):\n",
        "                    if off_start >= start_char and off_end <= end_char:\n",
        "                        prefix = 'B-' if off_start == start_char else 'I-'\n",
        "                        labels[idx] = label2id.get(f\"{prefix}{ent_type}\", label2id['O'])\n",
        "    encoding.pop('offset_mapping')\n",
        "    encoding['labels'] = labels\n",
        "    return encoding\n",
        "\n",
        "# Split original dataset into train and validation (preserve raw columns)\n",
        "all_indices = list(range(len(dataset)))\n",
        "train_idx, val_idx = train_test_split(all_indices, test_size=0.1, random_state=42)\n",
        "train_orig = dataset.select(train_idx)\n",
        "val_orig = dataset.select(val_idx)\n",
        "print(f\"Original train size: {len(train_orig)}, validation size: {len(val_orig)}\")\n",
        "\n",
        "# Tokenize & align labels separately, removing raw columns only from tokenized sets\n",
        "train_tok = train_orig.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=False,\n",
        "    remove_columns=['domain','title','doc','triples','entities','label_set','entity_label_set']\n",
        ")\n",
        "val_tok = val_orig.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=False,\n",
        "    remove_columns=['domain','title','doc','triples','entities','label_set','entity_label_set']\n",
        ")\n",
        "print(f\"Documents truncated in training: {trunc_count} / {len(train_tok)}\")\n",
        "\n",
        "# Use tokenized datasets for training and evaluation\n",
        "train_ds = train_tok\n",
        "val_ds = val_tok\n",
        "print(f\"Train set size: {len(train_ds)}, Validation set size: {len(val_ds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f7d0c48",
      "metadata": {
        "id": "1f7d0c48"
      },
      "source": [
        "# Baseline NER with Untrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "025d714b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "025d714b",
        "outputId": "0d49eee5-6893-4e59-c913-3b8c1c0cb1b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved validation NER predictions to drive/MyDrive/dataset/processed/ner_untrained_predictions.json\n",
            "NER Validation Mention-level Metrics:\n",
            "{'precision': 0.0002937720329024677, 'recall': 0.0025380710659898475, 'f1': 0.0005265929436545551, 'true_positives': 1, 'predicted': 3404, 'gold': 394}\n",
            "Saved evaluation metrics to drive/MyDrive/dataset/processed/ner_untrained_scores.json\n"
          ]
        }
      ],
      "source": [
        "# Create NER pipeline using the fine-tuned model\n",
        "ner_pipe_untrained = pipeline(\n",
        "    'ner',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0,\n",
        "    aggregation_strategy='simple'\n",
        ")\n",
        "\n",
        "# Run NER on validation documents and collect aggregated results\n",
        "val_results = []\n",
        "for idx, example in enumerate(val_orig):\n",
        "    preds = ner_pipe_untrained(example['doc'])\n",
        "    val_results.append({\n",
        "        'index': idx,\n",
        "        'doc_title': example.get('title', f'doc_{idx}'),\n",
        "        'predictions': preds\n",
        "    })\n",
        "\n",
        "# Save to JSON in Google Drive folder\n",
        "output_path = f'{base_path}processed/ner_untrained_predictions.json'\n",
        "save_model_output(val_results, output_path)\n",
        "\n",
        "scores_path = f'{base_path}processed/ner_untrained_scores.json'\n",
        "compute_f1(output_path, scores_path, val_orig)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "569023bb",
      "metadata": {
        "id": "569023bb"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b9b30c2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9b30c2f",
        "outputId": "a5859efe-c3c5-4d5b-c987-a1c5e95b372a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using learning_rate=0.001, batch_size=2, epochs=5, warmup_steps=34, weight_decay=0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-69bcbadf3799>:85: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "# Training arguments\n",
        "train_batch_size = 2\n",
        "gradient_accumulation_steps = 1\n",
        "num_epochs = 5\n",
        "learning_rate = 1e-3\n",
        "total_steps = math.ceil(len(train_ds) / train_batch_size / gradient_accumulation_steps) * num_epochs\n",
        "warmup_steps = int(total_steps * 0.1)\n",
        "print(f\"Using learning_rate={learning_rate}, batch_size={train_batch_size}, epochs={num_epochs}, warmup_steps={warmup_steps}, weight_decay=0.01\")\n",
        "\n",
        "\"\"\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./models/longformer-ner',\n",
        "    num_train_epochs=num_epochs,\n",
        "    learning_rate=learning_rate,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    per_device_train_batch_size=train_batch_size,\n",
        "    per_device_eval_batch_size=train_batch_size,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=0.01,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,\n",
        "    save_total_limit=2,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1'\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./models/longformer-ner',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    save_steps=1000\n",
        ")\n",
        "\n",
        "# Metric computation\n",
        "evaluator = evaluate.load('seqeval')\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    preds = predictions.argmax(-1)\n",
        "    true_labels = [[id2label[l] for l in label_seq if l != -100] for label_seq in labels]\n",
        "    true_preds = [[id2label[p_] for (p_, l) in zip(pred_seq, label_seq) if l != -100]\n",
        "                  for pred_seq, label_seq in zip(preds, labels)]\n",
        "    results = evaluator.compute(predictions=true_preds, references=true_labels)\n",
        "    return {\n",
        "        'precision': results['overall_precision'],\n",
        "        'recall': results['overall_recall'],\n",
        "        'f1': results['overall_f1']\n",
        "    }\n",
        "\n",
        "class StopOnZeroLossCallback(TrainerCallback):\n",
        "    \"\"\"Stop training when training loss stays at 0 for more than one logging step.\"\"\"\n",
        "    def __init__(self, patience=1):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.last_loss = None\n",
        "\n",
        "    def on_log(self, args, state: TrainerState, control: TrainerControl, logs=None, **kwargs):\n",
        "        loss = logs.get('loss')\n",
        "        if loss is not None:\n",
        "            if loss == 0:\n",
        "                if self.last_loss == 0:\n",
        "                    self.counter += 1\n",
        "                else:\n",
        "                    self.counter = 1\n",
        "                self.last_loss = loss\n",
        "                if self.counter > self.patience:\n",
        "                    print(\"Stopping training as loss has remained at 0 for {} steps.\".format(self.counter))\n",
        "                    control.should_training_stop = True\n",
        "            else:\n",
        "                # reset counter if loss > 0\n",
        "                self.counter = 0\n",
        "                self.last_loss = loss\n",
        "        return control\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[StopOnZeroLossCallback(patience=1)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "\n",
        "print(f\"Total truncated documents: {trunc_count} / {len(dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "YOGKCutIGFU4",
        "outputId": "0e9732c6-60b8-4a8f-f297-2050486b3e6d"
      },
      "id": "YOGKCutIGFU4",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/675 01:07 < 00:23, 7.34 it/s, Epoch 3/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.256900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.273200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopping training as loss has remained at 0 for 2 steps.\n",
            "Total truncated documents: 151 / 151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca63db25",
      "metadata": {
        "id": "ca63db25"
      },
      "source": [
        "# NER on Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d6e97528",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6e97528",
        "outputId": "96d55c8a-192d-4ccd-c4d8-8c37262c5049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/token_classification.py:512: RuntimeWarning: Mean of empty slice\n",
            "  scores = np.nanmean([entity[\"score\"] for entity in entities])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved validation NER predictions to drive/MyDrive/dataset/processed/ner_trained_predictions.json\n",
            "NER Validation Mention-level Metrics:\n",
            "{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'true_positives': 0, 'predicted': 0, 'gold': 394}\n",
            "Saved evaluation metrics to drive/MyDrive/dataset/processed/ner_trained_scores.json\n"
          ]
        }
      ],
      "source": [
        "# Create NER pipeline using the fine-tuned model\n",
        "ner_pipe_finetuned = pipeline(\n",
        "    'ner',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0,\n",
        "    aggregation_strategy='simple'\n",
        ")\n",
        "\n",
        "# Run NER on validation documents and collect aggregated results\n",
        "val_results = []\n",
        "for idx, example in enumerate(val_orig):\n",
        "    preds = ner_pipe_finetuned(example['doc'])\n",
        "    val_results.append({\n",
        "        'index': idx,\n",
        "        #'doc_title': example.get('title', f'doc_{idx}'),\n",
        "        'predictions': preds\n",
        "    })\n",
        "\n",
        "# Save to JSON in Google Drive folder\n",
        "output_path = f'{base_path}processed/ner_trained_predictions.json'\n",
        "save_model_output(val_results, output_path)\n",
        "\n",
        "scores_path = f'{base_path}processed/ner_trained_scores.json'\n",
        "compute_f1(output_path, scores_path, val_orig)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp_project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "802642f6f9324572a46462469b17c2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d263c6f3bef7483da602a1030ec36245",
              "IPY_MODEL_6ad22ddb7189453c953935408c8798af",
              "IPY_MODEL_f8d0e89b1a6b4118a66f847bab5cc546"
            ],
            "layout": "IPY_MODEL_62e99c1bd15344c6b179764657fee6f4"
          }
        },
        "d263c6f3bef7483da602a1030ec36245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20625b1874bf4164bf046fe4534e64b3",
            "placeholder": "​",
            "style": "IPY_MODEL_de2df7a9eb114d2ab6947a7f2222eec3",
            "value": "Map: 100%"
          }
        },
        "6ad22ddb7189453c953935408c8798af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c32a482eec014343ab8abc9063cfd57b",
            "max": 135,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9090c82ae404298af0a61b1cce426ce",
            "value": 135
          }
        },
        "f8d0e89b1a6b4118a66f847bab5cc546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64aaa6ddbf4a460e9f91128db7562023",
            "placeholder": "​",
            "style": "IPY_MODEL_94481d1049704319ac804d7966683dad",
            "value": " 135/135 [00:00&lt;00:00, 152.26 examples/s]"
          }
        },
        "62e99c1bd15344c6b179764657fee6f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20625b1874bf4164bf046fe4534e64b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de2df7a9eb114d2ab6947a7f2222eec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c32a482eec014343ab8abc9063cfd57b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9090c82ae404298af0a61b1cce426ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64aaa6ddbf4a460e9f91128db7562023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94481d1049704319ac804d7966683dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "566903f7ee8f4ae7a240f779f2b15dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82645ad12cd7479d90be0fab7c0610af",
              "IPY_MODEL_8e31ead02b514327aad3ddecc2af9b42",
              "IPY_MODEL_843712ac4d5043d48326852cf93b32b3"
            ],
            "layout": "IPY_MODEL_7bd420efc4be4266bda94e889c2701d2"
          }
        },
        "82645ad12cd7479d90be0fab7c0610af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_364595c4ba24420ba32ab2ea31dfb03c",
            "placeholder": "​",
            "style": "IPY_MODEL_28a61c0f858f414e95251022fd46c5b9",
            "value": "Map: 100%"
          }
        },
        "8e31ead02b514327aad3ddecc2af9b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31edae985ea2481da76f60d14aabe5d6",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0371e9c862d486fa9843d62ee1baebc",
            "value": 16
          }
        },
        "843712ac4d5043d48326852cf93b32b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27c5560addef48f78318f7cc39b22ec1",
            "placeholder": "​",
            "style": "IPY_MODEL_5292582c4ecf4bb0ac6f62209fb8c631",
            "value": " 16/16 [00:00&lt;00:00, 152.77 examples/s]"
          }
        },
        "7bd420efc4be4266bda94e889c2701d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "364595c4ba24420ba32ab2ea31dfb03c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28a61c0f858f414e95251022fd46c5b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31edae985ea2481da76f60d14aabe5d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0371e9c862d486fa9843d62ee1baebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27c5560addef48f78318f7cc39b22ec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5292582c4ecf4bb0ac6f62209fb8c631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}